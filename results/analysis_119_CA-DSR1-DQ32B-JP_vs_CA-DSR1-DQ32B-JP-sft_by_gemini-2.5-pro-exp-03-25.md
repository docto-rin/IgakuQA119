# LLM (gemini-2.5-pro-exp-03-25) による CA-DSR1-DQ32B-JP vs CA-DSR1-DQ32B-JP-SFT 誤答比較考察

分析実行日時: 2025-04-07 13:02:22

# LLMモデルの医師国家試験問題における誤答傾向比較・考察レポート

本レポートは、日本の医師国家試験（第119回）問題に対する2つのLLMモデル（**CA-DSR1-DQ32B-JP**、**CA-DSR1-DQ32B-JP-SFT**）の回答結果に基づき、その誤答傾向を比較・考察するものである。

## 1. 全体的な誤答傾向の比較

### 1.1 両モデルに共通する弱点や誤答しやすい問題タイプ

提供されたレポートによると、両モデルが共通して誤答した問題は61問存在した。これらの問題の傾向から、以下のタイプが両モデルにとって共通の弱点であると推測される。

*   **複雑な臨床推論問題:** 複数の情報（病歴、身体所見、検査データ、画像所見など）を統合し、診断や治療方針を決定する必要がある問題。特に鑑別診断が難しい症例や、複数の病態が絡み合う場合に誤答が多い傾向が見られる (例: 119A21, 119A22, 119D17, 119D40)。
*   **画像解釈を伴う問題:** X線、CT、MRI、心電図、病理組織像、眼底写真などの画像情報を正確に解釈し、臨床情報と結びつけて解答する必要がある問題。画像の特徴的な所見を見落としたり、誤って解釈したりするケースが見られる (例: 119A15, 119A21, 119A50, 119C40, 119D10, 119E12)。
*   **計算問題:** 水分出納バランス (119A75)、Na欠乏量 (119F75)、A-aDO2 (119C74)、尤度比を用いた事後確率 (119E39) など、計算が必要な問題で両モデルとも誤答している。計算式の誤解や適用ミス、単純な計算ミスが原因と考えられる。
*   **特定の知識問題:**
    *   **医療制度・法規・公衆衛生:** 119B5 (設置主体)、119C14 (就業制限通知)、119C19 (母子保健法)、119F8 (健康診断規定)、119F10 (国民生活基礎調査)、119F31 (基準病床数) など、特定の法律や制度に関する正確な知識が問われる問題。
    *   **統計・疫学:** 119C2 (高齢化率グラフ)、119F22 (母体年齢別出生割合) など、統計データの解釈や知識が問われる問題。
    *   **基礎医学（解剖・生理・遺伝学など）:** 119C33 (冠動脈解剖)、119E17 (染色体遺伝子数)、119E20 (脊髄レベル)、119F2 (大腿静脈解剖)、119F30 (新生児生理) など、基礎的な医学知識の正確性が求められる問題。
*   **臨床判断が分かれる可能性のある問題:** 救急対応の優先順位 (119B26)、感染症罹患時の登校基準 (119C52) など、ガイドラインや状況によって判断が微妙に異なる可能性のある問題。

### 1.2 各モデルの誤答傾向の違い

*   **CA-DSR1-DQ32B-JP (基盤モデル):**
    *   **SFTモデル**が正答した47問で誤答。
    *   誤答は知識問題、臨床推論、治療選択、概念理解など多岐にわたる。
    *   説明文からは、時に一般的でない知識や推論プロセスに依存したり (例: 119A18, 119A41)、問題文の特定の情報に過度に注目したりする傾向がうかがえる。
    *   計算問題 (119E39) やROC曲線解釈 (119E23) など、特定の応用問題での誤りも見られる。
*   **CA-DSR1-DQ32B-JP-SFT (Fine-tunedモデル):**
    *   **基盤モデル**が正答した53問で誤答。誤答総数は**基盤モデル**よりわずかに多い。
    *   誤答タイプは**基盤モデル**と同様に多岐にわたるが、特に臨床推論や治療選択における誤りが目立つ。
    *   説明文からは、主要な所見を見落としたり、特定の疾患や病態に固執したりする傾向 (例: 119A51, 119D36)、あるいは臨床的な優先順位付けを誤る傾向 (例: 119A15) が見られることがある。
    *   複数選択問題で要求される選択肢数を選べていないケースがある (例: 119D73, 119D74, 119F34)。これはFine-tuningの過程で単数選択問題に偏った学習がされた可能性、あるいは出力形式の制御に課題がある可能性を示唆する。
    *   計算問題 (119C74, 119F75) や基礎知識 (119B9 大動脈弁狭窄症の聴診部位) での誤りも見られる。

### 1.3 片方のみの誤答から推測される強み・弱み

*   **CA-DSR1-DQ32B-JP:** **SFTモデル**が間違えた53問を正答していることから、基盤モデルとして幅広い知識や推論能力を保持しており、Fine-tuningされていない領域や問題タイプにおいて**SFTモデル**よりも安定した性能を示す可能性がある。
*   **CA-DSR1-DQ32B-JP-SFT:** **基盤モデル**が間違えた47問を正答している。これはFine-tuningによって、医師国家試験で問われる特定の知識や問題形式への適応度が向上していることを示唆する。特に、**基盤モデル**が一般的でない推論で誤答した際に、**SFTモデル**はより標準的な医学知識に基づいて正答している可能性がある。
*   **総評:** 両モデルとも一長一短があり、現時点ではどちらかが明確に優れているとは言い難い。**SFTモデル**はFine-tuningによる試験適応が見られる一方で、基盤モデルが持つ弱点を完全に克服できておらず、新たな弱点（複数選択問題への対応など）が生じている可能性もある。問題ごとに得意不得意が分かれる状況と考えられる。

## 2. 具体的な誤答パターンの分析

### 2.1 「両モデル共通誤答のパターン」の分析

`Both_Wrong`レポートの共通誤答パターンを見ると、`Correct:a | JP:b | SFT:b` (3件)、`Correct:b | JP:c | SFT:c` (3件)、`Correct:d | JP:e | SFT:e` (3件) など、両モデルが全く同じ誤った選択肢を選んでいるケースが複数存在する。この原因としては以下が考えられる。

*   **魅力的な誤答選択肢:** 問題作成者が意図的に配置した、正解に類似しているが誤りである選択肢や、一般的な誤解に基づいた選択肢に、両モデルが同様に引きつけられた可能性。
*   **共通の知識欠落・誤解:** 特定の疾患、病態、治療法、ガイドラインに関する知識が両モデルの学習データに不足している、あるいは誤って学習されている可能性。特に比較的新しい知見や稀な疾患に関する問題で起こりやすい。
*   **問題文解釈の共通の誤り:** 問題文のニュアンスや条件設定の解釈を両モデルが同様に誤った可能性。
*   **LLM特有のバイアス:** 学習データ中の出現頻度や共起関係に基づいて、医学的な正確性よりも統計的にもっともらしい選択肢を選んでしまう傾向。

一方で、`Correct:e | JP:b | SFT:d` (3件) のように、両モデルが異なる誤答選択肢を選んでいるケースも多数存在する。これは、両者が異なる知識や推論プロセスに基づいて解答を導き出していることを示唆しており、単一の原因だけでは説明できない多様な誤答メカニズムが存在することを示している。

### 2.2 各モデルの誤答理由（説明）からの原因推測

提供された説明文から、誤答の原因を推測する。

*   **知識不足・不正確な知識:**
    *   特定の疾患知識 (例: 119A22 膠原病、119D6 大腿骨頭壊死症関連疾患)
    *   検査所見の解釈 (例: 119C10 尿沈渣、119C15 蛋白電気泳動、119C40 呼吸機能検査)
    *   薬物作用部位 (119A10) や治療適応 (例: 119A41 機能性ディスペプシア、119F69 心筋梗塞)
    *   解剖学的知識 (例: 119B9 聴診部位、119F2 大腿静脈周囲)
    *   制度・統計知識 (例: 119B5, 119C2, 119C14, 119F10, 119F17, 119F22)
    *   計算式の誤解・適用ミス (例: 119A75, 119C74, 119E39, 119F75)
*   **読解ミス・問題意図の誤解:**
    *   問題文の条件や数値を読み間違える (例: 119E39 スコア計算ミス)
    *   下線部の意図を誤解する (例: 119B41 重要でない情報の選択)
    *   複数選択問題で選択数が不足する (**SFTモデル**の一部)
*   **推論の誤り:**
    *   提示された情報（特に画像所見）の解釈を誤り、不適切な診断・治療選択に至る (例: 119A15, 119A50, 119D21)。
    *   複数の情報の中から重要度の低い情報に注目しすぎたり、重要な情報を見落としたりする (例: 119A50, 119B41)。
    *   鑑別診断のプロセスで、可能性の低い疾患に固執したり、最も可能性の高い疾患を除外したりする (例: 119A51, 119D36)。
    *   臨床的な優先順位付けを誤る (例: 119A15, 119B26, 119D69)。
*   **LLM特有の傾向:**
    *   もっともらしいが医学的に不正確な理由付けを行う（ハルシネーションの可能性）。
    *   選択肢に引きずられ、本来最も可能性の高い診断・治療から逸脱する (例: 119A22)。

Fine-tuningされた**SFTモデル**においても、知識不足、読解ミス、推論の誤りといった基盤モデルと同様の原因が見られることは注目に値する。これは、Fine-tuningが特定のタスクへの適合性を高める一方で、基盤モデルが持つ根本的な課題を完全に解決するわけではないことを示唆している。

## 3. 総括

### 3.1 全体的な性能・特性

*   **CA-DSR1-DQ32B-JP**と**CA-DSR1-DQ32B-JP-SFT**は、日本の医師国家試験問題に対して一定の解答能力を示すものの、依然として多くの課題を抱えている。
*   誤答傾向には共通点が多く、特に複雑な臨床推論、画像解釈、計算問題、特定の知識領域（制度、統計、基礎医学など）が両モデルにとって難関であることが示唆される。
*   **SFTモデル**はFine-tuningにより特定の試験形式への適応が見られる可能性があるが、誤答総数では**基盤モデル**をわずかに上回り、複数選択問題への対応など新たな課題も抱えている可能性がある。現時点での明確な優劣はつけ難い。
*   両モデルとも、誤答時に医学的に不正確な推論や理由付けを行うことがあり、LLMとしての限界（ハルシネーション、統計的もっともらしさへの偏り）を示している。

### 3.2 改善の方向性

両モデルの性能向上のためには、以下の方向性が考えられる。

*   **学習データの質と量の向上:**
    *   最新かつ正確な医学知識、臨床ガイドライン、エビデンスに基づく学習。
    *   多様な症例、特に診断や治療方針の判断が難しい症例データの拡充。
    *   医療画像（X線、CT、MRI、心電図、病理像等）とその解釈に関するマルチモーダル学習の強化。
    *   計算問題、統計解釈、医療制度・法規に関するデータの拡充。
*   **推論能力の強化:**
    *   Chain-of-Thoughtプロンプティングなどを活用し、段階的かつ論理的な思考プロセスを強化。
    *   臨床医の思考プロセス（鑑別診断、治療方針決定など）を模倣するような学習フレームワークの導入。
    *   自己修正能力（Self-Correction）の導入による誤答の自律的検出・修正。
*   **Fine-tuning戦略の最適化 (SFTモデル):**
    *   単なる正答の学習だけでなく、誤答分析や正しい推論プロセスの学習を取り入れる。
    *   複数選択問題や計算問題など、多様な問題形式への対応力を強化する。
    *   医師国家試験の出題傾向や評価基準に合わせたチューニング。
*   **外部知識ベースとの連携 (RAGなど):**
    *   信頼性の高い医学データベースや知識グラフを参照しながら回答を生成する仕組みを導入し、知識の正確性と網羅性を向上させる。
*   **プロンプトエンジニアリングの活用:**
    *   問題の核心を捉え、必要な情報を引き出し、段階的な思考を促すような効果的なプロンプト設計。

これらの改善を通じて、LLMが医療分野、特に医学教育や臨床意思決定支援において、より信頼性の高いツールとなることが期待される。
